{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_data_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1mp9GACuCPtjgqqxXVBB3K1_L6opN6aIR",
      "authorship_tag": "ABX9TyM3VbIzocgX7qGKsgs2T7MS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niloy28/NurseActivityRecognition/blob/master/lab_data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwTPVQAuw25g",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Download and extract the dataset\n",
        "\n",
        "URL = \"https://ieee-dataport.s3.amazonaws.com/open/11167/Training.zip?response-content-disposition=attachment%3B%20filename%3D%22Training.zip%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJOHYI4KJCE6Q7MIQ%2F20200616%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200616T082632Z&X-Amz-SignedHeaders=Host&X-Amz-Expires=86400&X-Amz-Signature=945354b7acb38f2172b8978a73ceffbf5943e91a14442c7314dbb666430fb079\" #@param {type : \"string\"} \n",
        "savepath = \"Training.zip\" #@param {type : 'string'}\n",
        "extractpath = \"/content/dataset/\" #@param {type : 'string'}\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlretrieve\n",
        "import os\n",
        "\n",
        "if not os.path.isfile(savepath):\n",
        "  urlretrieve(URL, savepath)\n",
        "with ZipFile(savepath, 'r') as zip_file:\n",
        "  zip_file.extractall(extractpath)\n",
        "\n",
        "!rm -rf /content/sample_data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtxlnIPX3mUr",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install Dependencies\n",
        "from google.colab import files\n",
        "\n",
        "in_file = files.upload()\n",
        "\n",
        "if len(in_file.keys()) == 1:\n",
        "  for fn in in_file.keys():\n",
        "    requirement = \"/content/\" + str(fn)\n",
        "\n",
        "!pip install -r $requirement"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "615YqgUK3ItS",
        "colab_type": "text"
      },
      "source": [
        "<h1> Import Dependencies </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCBdx0Jqv80p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import datetime\n",
        "import dateutil"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uueFrsUOfZkR",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Loading the lab dataset\n",
        "accel_dataset_file = \"/content/drive/My Drive/nurse care data/training/Lab/bigact_raw_lab_acc.csv\" #@param {type : \"string\"}\n",
        "label_dataset_file = \"/content/drive/My Drive/nurse care data/training/Lab/labels_lab_2users.csv\" #@param {type : \"string\"}\n",
        "ignore_seconds = True #@param {type : \"boolean\"}\n",
        "\n",
        "accel_dataset = pd.read_csv(accel_dataset_file)\n",
        "accel_dataset['datetime'] = [x[0:-5] for x in accel_dataset['datetime']]\n",
        "accel_dataset['datetime'] = pd.to_datetime(accel_dataset['datetime'])\n",
        "\n",
        "label_dataset = pd.read_csv(label_dataset_file, na_filter=False, parse_dates=[2, 3], infer_datetime_format=True)\n",
        "\n",
        "if ignore_seconds:\n",
        "    accel_dataset['datetime'] = [pd.Timestamp.replace(x, second=0, microsecond=0) for x in accel_dataset['datetime']]\n",
        "    label_dataset['start'] = [pd.Timestamp.replace(x, second=0, microsecond=0) for x in label_dataset['start']]\n",
        "    label_dataset['finish'] = [pd.Timestamp.replace(x, second=0, microsecond=0) for x in label_dataset['finish']]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vTebKSs7-bq",
        "colab_type": "text"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUB98wehsCMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accel_user1 = accel_dataset[accel_dataset['user_id'] == 1]\n",
        "accel_user19 = accel_dataset[accel_dataset['user_id'] == 19]\n",
        "\n",
        "label_user1 = label_dataset[label_dataset['user_id'] == 1]\n",
        "label_user19 = label_dataset[label_dataset['user_id'] == 19]\n",
        "\n",
        "label_user1.reset_index(drop=True, inplace=True)\n",
        "label_user19.reset_index(drop=True, inplace=True)\n",
        "accel_user1.reset_index(drop=True, inplace=True)\n",
        "accel_user19.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khXVe3xZzPSN",
        "colab_type": "text"
      },
      "source": [
        "### Extract accelerometer data that corresponds to label datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYH0yteu2WHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_aligned_dataset = []\n",
        "\n",
        "# user 1\n",
        "for i in label_user1.index.values:\n",
        "  start_date = label_user1.at[i, 'start']\n",
        "  end_date = label_user1.at[i, 'finish']\n",
        "\n",
        "  mask = ((accel_user1['datetime']  >= start_date) & (accel_user1['datetime'] <= end_date))\n",
        "  \n",
        "  masked_dataset = accel_user1.loc[mask].loc[:, ['x', 'y', 'z']]\n",
        "  if not masked_dataset.empty:\n",
        "    act_series = pd.Series(label_user1.iat[i, 1]).repeat(masked_dataset.shape[0])\n",
        "    \n",
        "    # must reset index for concat to succeed\n",
        "    act_series.reset_index(drop=True, inplace=True)\n",
        "    masked_dataset.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "    chunk = pd.concat([masked_dataset, act_series], ignore_index=True, axis=1)\n",
        "    final_aligned_dataset.append(chunk)\n",
        "\n",
        "# user 19\n",
        "for i in label_user19.index.values:\n",
        "  start_date = label_user19.at[i, 'start']\n",
        "  end_date = label_user19.at[i, 'finish']\n",
        "\n",
        "  mask = ((accel_user19['datetime']  >= start_date) & (accel_user19['datetime'] <= end_date))\n",
        "  \n",
        "  masked_dataset = accel_user19.loc[mask].loc[:, ['x', 'y', 'z']]\n",
        "  if not masked_dataset.empty:\n",
        "    act_series = pd.Series(label_user19.iat[i, 1]).repeat(masked_dataset.shape[0])\n",
        "    \n",
        "    # must reset index for concat to succeed\n",
        "    act_series.reset_index(drop=True, inplace=True)\n",
        "    masked_dataset.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "    chunk = pd.concat([masked_dataset, act_series], ignore_index=True, axis=1)\n",
        "    final_aligned_dataset.append(chunk)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggxpLKZIqFbC",
        "colab_type": "text"
      },
      "source": [
        "### Generate aligned dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCZBnLauqJpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_aligned_dataset = pd.concat(final_aligned_dataset)\n",
        "final_aligned_dataset.columns = ['x', 'y', 'z', 'act_id']\n",
        "final_aligned_dataset.drop_duplicates(inplace=True, ignore_index=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-E5jaKkqBNi",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Save aligned data as csv\n",
        "\n",
        "savepath = \"/content/processed\" #@param {type : 'string'}\n",
        "savename = \"final_lab.csv\" #@param {type : 'string'}\n",
        "\n",
        "import os\n",
        "os.makedirs(savepath, exist_ok=True)\n",
        "\n",
        "complete_savename = savepath + \"/\" + savename\n",
        "final_aligned_dataset.to_csv(complete_savename, index=False)"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}