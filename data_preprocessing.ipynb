{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "data_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwTPVQAuw25g",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Download and extract the dataset\n",
        "\n",
        "URL = \"https://ieee-dataport.s3.amazonaws.com/open/11167/Training.zip?response-content-disposition=attachment%3B%20filename%3D%22Training.zip%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJOHYI4KJCE6Q7MIQ%2F20200616%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200616T082632Z&X-Amz-SignedHeaders=Host&X-Amz-Expires=86400&X-Amz-Signature=945354b7acb38f2172b8978a73ceffbf5943e91a14442c7314dbb666430fb079\" #@param {type : \"string\"} \n",
        "savepath = \"Training.zip\" #@param {type : 'string'}\n",
        "extractpath = \"/content/dataset/\" #@param {type : 'string'}\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlretrieve\n",
        "import os\n",
        "\n",
        "if not os.path.isfile(savepath):\n",
        "  urlretrieve(URL, savepath)\n",
        "with ZipFile(savepath, 'r') as zip_file:\n",
        "  zip_file.extractall(extractpath)\n",
        "\n",
        "!rm -rf /content/sample_data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtxlnIPX3mUr",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install Dependencies\n",
        "from google.colab import files\n",
        "\n",
        "in_file = files.upload()\n",
        "\n",
        "if len(in_file.keys()) == 1:\n",
        "  for fn in in_file.keys():\n",
        "    requirement = \"/content/\" + str(fn)\n",
        "\n",
        "!pip install -r $requirement"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "615YqgUK3ItS",
        "colab_type": "text"
      },
      "source": [
        "<h1> Import Dependencies </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCBdx0Jqv80p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import datetime\n",
        "import dateutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpx-YjFVv802",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Loading the dataset\n",
        "\n",
        "accel_dataset_file = \"/content/dataset/Field/raw_field_acc_user51.csv\" #@param {type : \"string\"}\n",
        "label_dataset_file = \"/content/dataset/Field/field_label_train.csv\" #@param {type : \"string\"}\n",
        "\n",
        "accel_dataset = pd.read_csv(accel_dataset_file, na_filter=False, parse_dates=[1], infer_datetime_format=True, date_parser=lambda col : pd.to_datetime(col, utc=True))\n",
        "label_dataset = pd.read_csv(label_dataset_file, na_filter=False, parse_dates=[2, 3], infer_datetime_format=True, date_parser=lambda col : pd.to_datetime(col, utc=True))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KTDvLc4Te3y",
        "colab_type": "text"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqJ5FWorYscK",
        "colab_type": "text"
      },
      "source": [
        "<h3> Sort the values according to datetime </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIBur-GqTbvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accel_dataset = pd.DataFrame.sort_values(accel_dataset, ['datetime'], ignore_index=True)\n",
        "label_dataset = pd.DataFrame.sort_values(label_dataset, ['start', 'finish'], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGtDane5hBcq",
        "colab_type": "text"
      },
      "source": [
        "<h3> Truncate rows from accelerometer dataset whose datetime that do not correspond with label dataset datetime </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWGCXC31hQ_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_first_time_entry = label_dataset.iloc[0].loc['start']\n",
        "label_last_time_entry = label_dataset.iloc[-1].loc['start']\n",
        "\n",
        "trunc_accel_dataset = accel_dataset[accel_dataset['datetime'] >= label_first_time_entry]\n",
        "trunc_accel_dataset = trunc_accel_dataset[trunc_accel_dataset['datetime'] <= label_last_time_entry]\n",
        "trunc_accel_dataset.reset_index(drop=True, inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khXVe3xZzPSN",
        "colab_type": "text"
      },
      "source": [
        "<h3> Extract accelerometer data that corresponds to label datetime </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp-3QN9pzlER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_aligned_dataset = []\n",
        "\n",
        "for i in label_dataset.index.values:\n",
        "  start_date = label_dataset.at[i, 'start']\n",
        "  end_date = label_dataset.at[i, 'finish']\n",
        "  user_id = label_dataset.at[i, 'user_id']\n",
        "\n",
        "  mask = ((trunc_accel_dataset['datetime']  >= start_date) & (trunc_accel_dataset['datetime'] <= end_date) & (trunc_accel_dataset['user_id'] == user_id))\n",
        "  \n",
        "  masked_dataset = trunc_accel_dataset.loc[mask].loc[:, ['x', 'y', 'z']]\n",
        "  if not masked_dataset.empty:\n",
        "    act_series = pd.Series(label_dataset.iat[i, 1]).repeat(masked_dataset.shape[0])\n",
        "    \n",
        "    # must reset index for concat to succeed\n",
        "    act_series.reset_index(drop=True, inplace=True)\n",
        "    masked_dataset.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "    chunk = pd.concat([masked_dataset, act_series], ignore_index=True, axis=1)\n",
        "    final_aligned_dataset.append(chunk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggxpLKZIqFbC",
        "colab_type": "text"
      },
      "source": [
        "<h3> Generate aligned dataframe </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCZBnLauqJpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_aligned_dataset = pd.concat(final_aligned_dataset)\n",
        "final_aligned_dataset.columns = ['x', 'y', 'z', 'act_id']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-E5jaKkqBNi",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Save aligned data as csv\n",
        "\n",
        "savepath = \"/content/processed\" #@param {type : 'string'}\n",
        "savename = \"final_field_user51_dataset.csv\" #@param {type : 'string'}\n",
        "\n",
        "import os\n",
        "os.makedirs(savepath, exist_ok=True)\n",
        "\n",
        "complete_savename = savepath + \"/\" + savename\n",
        "final_aligned_dataset.to_csv(complete_savename, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}